{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week Two\n",
    "---\n",
    "- logistic回归\n",
    "- 使用numpy对计算向量化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二分类器-logistics回归\n",
    "\n",
    "分类器的预测值是$P(\\hat{Y}=1|x)$, 使得概率尽可能与实际标签相符.logistics回归使用logit模型将$W^TX+b$映射到0-1, 以下表达式也称为sigmoid函数\n",
    "$$\\sigma(z) = \\frac{1}{1+e^{-z}}$$\n",
    "> sigmoid函数的求导特点:$\\sigma\\prime(z) = \\sigma(z)(1-\\sigma(z))$\n",
    "\n",
    "**loss函数**: 评价预测值与真实值之间的差距\n",
    "$$L(\\hat{y}, y)=-(ylog\\hat{y}+(1-y)log(1-\\hat{y}))$$\n",
    "> 为什么要使用交叉熵而不使用方差作为loss函数?\n",
    "传统回归方法可以采用MSE方法, 当采用sigmoid函数做分类时, MSE方法对W和b的求导与simoid函数的导数有关, 在两侧sigmoid导数小, 下降慢, 但是采用CrossEtropy时, loss函数对W和b的导数只与$\\hat{y}-y$相关, 具有更好的下降性质, 其他回归采用MSE方法可行的原因是预测函数性质不同, 不具有sigmoid的性质. 详见[交叉熵](https://zhuanlan.zhihu.com/p/61944055). Andrew也给出另一方面的解释, MSE是非凸函数,其在使用梯度下降算法时容易陷入局部最优解, 因此这里要采用凸函数.\n",
    "\n",
    "**Cost函数**:以当前的W和b参数进行预测产生的成本,即平均loss\n",
    "$$J(W, b) = \\frac{1}{m} \\sum_{i} L(\\hat{y_i}, y_i)$$\n",
    "\n",
    "**推导计算与反向传播**\n",
    "\n",
    "正向计算是从输入到输出的计算过程, 反向传播使用链式法则, 对W和b的每一维求J的偏导\n",
    "![](src/pictures/c1_w1_1.png)\n",
    "\n",
    "在LR中,参数的反向传播推导略,结果为\n",
    "$$dw = \\frac{1}{m}\\sum_{i}^{m}(A_i - Y_i)X_i \\\\ db = \\frac{1}{m}\\sum_{i}^{m}A_i - Y_i$$\n",
    "\n",
    "## numpy中的广播机制\n",
    "\n",
    "- 如果两个数组的后缘维度的轴长度相符或其中一方的轴长度为1，则认为它们是广播兼容的。广播会在缺失维度和轴长度为1的维度上进行。\n",
    "- 后缘维度的轴长度：A.shape[-1] 即矩阵维度元组中的最后一个位置的值\n",
    "- 虽然在Python有广播的机制，但是在Python程序中，为了保证矩阵运算的正确性，可以使用reshape()函数来对矩阵设定所需要进行计算的维度，这是个好的习惯；\n",
    "\n",
    "    如果用下列语句来定义一个向量，则这条语句生成的a的维度为（5，），既不是行向量也不是列向量，称为秩（rank）为1的array，如果对a进行转置，则会得到a本身，这在计算中会给我们带来一些问题。\n",
    "    ```python\n",
    "    a = np.random.randn(5)\n",
    "    ```\n",
    "    如果需要定义（5，1）或者（1，5）向量，要使用下面标准的语句：\n",
    "    ```python\n",
    "    a = np.random.randn(5,1)\n",
    "    b = np.random.randn(1,5)\n",
    "```\n",
    "- 可以使用assert语句对向量或数组的维度进行判断。assert会对内嵌语句进行判断，即判断a的维度是不是（5，1），如果不是，则程序在此处停止。使用assert语句也是一种很好的习惯，能够帮助我们及时检查、发现语句是否正确。\n",
    "\n",
    "- 可以使用reshape函数对数组设定所需的维度\n",
    "```python\n",
    "a.reshape((5,1))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "X, y = load_digits(2, True)\n",
    "X_train,X_test,y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "y_train = y_train.reshape(y_train.shape[0], 1)\n",
    "y_test = y_test.reshape(y_test.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    '''\n",
    "    返回X的sigmoid函数值\n",
    "    x -- scale or numpy Array\n",
    "    '''\n",
    "    return 1./(1 + np.exp(-x))\n",
    "def normalize(x):\n",
    "    '''\n",
    "    将x标准化至0-1\n",
    "    '''\n",
    "    x_norm = np.linalg.norm(x, axis = 1, keepdims=True) # 计算array的行norm值\n",
    "    return x / x_norm\n",
    "\n",
    "def propagate(w, b, x, y):\n",
    "    '''\n",
    "    正反向传播的计算,返回正向的cost和反向的梯度\n",
    "    w--weights,(n, 1)\n",
    "    b--bias, 1\n",
    "    X--features,(m, n)\n",
    "    y--labels,(m, 1)\n",
    "    m-number of samples\n",
    "    n-dim of features\n",
    "    Return:\n",
    "    grads--gradients, dict\n",
    "    cost--array, ()\n",
    "    '''\n",
    "    m = x.shape[0]\n",
    "    z = x.dot(w) + b # (m, 1)\n",
    "    a = sigmoid(z)\n",
    "    dz = a - y\n",
    "    dw = (1./m) * x.T.dot(dz)\n",
    "    db = (1./m) * np.sum(dz)\n",
    "    cost = - (1./m) * (y.T.dot(np.log(a)) + (1-y).T.dot(np.log(1-a)))\n",
    "    cost = np.squeeze(cost) # 降维(1,1)->() \n",
    "    grads = {'dw':dw,\n",
    "           'db':db}\n",
    "    return grads, cost\n",
    "\n",
    "def initialize_with_zero(dim):\n",
    "    '''\n",
    "    用0初始化权重和偏置\n",
    "    dim-number of features\n",
    "    Return: parameters of dim and bias\n",
    "    '''\n",
    "    w = np.zeros((dim, 1))\n",
    "    b = 0\n",
    "    return w, b\n",
    "\n",
    "def optimize(w, b, X, Y, num_of_iterations, learning_rate, print_costs = False):\n",
    "    costs = []\n",
    "    for i in range(num_of_iterations):\n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        dw = grads['dw']\n",
    "        db = grads['db']\n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "        \n",
    "        if print_costs and i%100 == 0:\n",
    "            print(\"cost after iteration:%d is %f\" % (i, cost))\n",
    "        costs.append(cost)\n",
    "    params = {\"W\":w, \"b\":b}\n",
    "    grads = {\"dw\":dw, \"db\":db}\n",
    "    return params, grads, costs\n",
    "\n",
    "def predict(X, params):\n",
    "    W = params['W']\n",
    "    b = params['b']\n",
    "    z = sigmoid(np.dot(X, W) + b)\n",
    "    y_p = [1 if i > 0.5 else 0 for i in z]\n",
    "    y_p = np.array(y_p).reshape(z.shape)\n",
    "    return y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost after iteration:0 is 0.693147\n",
      "cost after iteration:100 is 0.005252\n",
      "cost after iteration:200 is 0.002916\n",
      "cost after iteration:300 is 0.002043\n",
      "cost after iteration:400 is 0.001580\n",
      "cost after iteration:500 is 0.001292\n",
      "cost after iteration:600 is 0.001094\n",
      "cost after iteration:700 is 0.000950\n",
      "cost after iteration:800 is 0.000840\n",
      "cost after iteration:900 is 0.000753\n"
     ]
    }
   ],
   "source": [
    "W, b = initialize_with_zero(X_train.shape[1])\n",
    "params, grads, costs = optimize(W, b, X_train, y_train, 1000, 0.01, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4519edcc50>]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(costs)), costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = predict(X_test, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(y_test - y_p))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
