{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week Three\n",
    "---\n",
    "- hidden units and hidden layers\n",
    "- variety of activation functions\n",
    "- forward and backward propagation with a hidden layer\n",
    "- random initialization\n",
    "\n",
    "课程参考:[coursera]()\n",
    "\n",
    "笔记参考:[c1_w3](https://blog.csdn.net/koala_tree/article/details/78059952)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络的表示和计算\n",
    "神经网络所做的事情, 直观上理解是上讲中逻辑回归的类似流程的多次重复. 对于每一个隐藏层节点,首先对X进行线性变换计算z, 然后通过激活函数进行非线性变换计算a. 神经网络的结构和表示如下图:\n",
    "<img src=\"src/pictures/c1_w3_1.png\" width=60%></img>\n",
    "正向传播的计算的向量表示可以描述为:\n",
    "<img src=\"src/pictures/c1_w3_2.png\" width=60%></img>\n",
    "\n",
    "\n",
    "## 激活函数\n",
    "\n",
    "常用的激活函数:\n",
    "- sigmoid函数:\n",
    "$$a = \\frac{1}{1+e^{-z}}$$\n",
    "- tanh函数:\n",
    "$$a = \\frac{e^{z} - e^{-z}}{e^z + e^{-z}} $$\n",
    "- ReLU函数:\n",
    "$$a = max(0, z)$$\n",
    "- Leaky ReLU函数：\n",
    "$$a = max(0.01z, z)$$\n",
    "\n",
    "### 激活函数的选择\n",
    "\n",
    "激活函数的选择：\n",
    "\n",
    "- sigmoid函数和tanh函数比较：\n",
    "\n",
    "    隐藏层：tanh函数的表现要好于sigmoid函数，因为tanh取值范围为[−1,+1][−1,+1]，输出分布在0值的附近，均值为0，从隐藏层到输出层数据起到了归一化（均值为0）的效果。\n",
    "    输出层：对于二分类任务的输出取值为{0,1}{0,1}，故一般会选择sigmoid函数。\n",
    "    然而sigmoid和tanh函数在当|z||z|很大的时候，梯度会很小，在依据梯度的算法中，更新在后期会变得很慢。在实际应用中，要使|z||z|尽可能的落在0值附近。\n",
    "\n",
    "ReLU弥补了前两者的缺陷，当z>0z>0时，梯度始终为1，从而提高神经网络基于梯度算法的运算速度。然而当z<0z<0时，梯度一直为0，但是实际的运用中，该缺陷的影响不是很大。\n",
    "\n",
    "Leaky ReLU保证在z<0z<0的时候，梯度仍然不为0。\n",
    "\n",
    "在选择激活函数的时候，如果在不知道该选什么的时候就选择ReLU，当然也没有固定答案，要依据实际问题在交叉验证集合中进行验证分析。\n",
    "\n",
    "## 神经网络的梯度下降法\n",
    "神经网络的学习即是各层节点的参数更新,更新通过梯度实现,各节点的梯度计算可以通过链式求导获得, 结果如下:\n",
    "<img src=\"src/pictures/c1_w3_3.png\" width=60%></img>\n",
    "\n",
    "## 随机初始化\n",
    "\n",
    "参数的初始化不能够采用全部初始化为0的策略, 会导致所有的节点都只能够学到相同的特征,因此初始化因采用随机数进行.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
