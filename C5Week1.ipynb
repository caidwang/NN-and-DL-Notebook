{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week1\n",
    "\n",
    "- Recurrent Neural Networks\n",
    "- GRU\n",
    "- LSTM\n",
    "- Deep RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN\n",
    "\n",
    "序列模型是输入一个序列输出一个序列的模型, 传统DNN不能解决输入长度与输出长度不统一的场景, 也不能解决在语言这类序列模型当中学习到位置信息并进行长程传递的问题, 即不能把一部分学到的东西快速的泛化到其他位置. RNN, 是为了解决序列模型的问题提出的模型\n",
    "\n",
    "### 基本结构\n",
    "\n",
    "<img src=\"src/pictures/c5_w1_1.jpg\" width=50%>\n",
    "\n",
    "RNN使用同一套纵向结构, 在时间维度上移动, 构成整体网络, 不同时间点共用同一套权重, 前面计算得到隐藏层值作为输入加入到后面时间点的计算中.\n",
    "\n",
    "#### 前向传播\n",
    "一个RNN cell的前向传播如下:\n",
    "$$a_t = g_1(W_{aa}a_{t-1} + W_{ax}X + b) \\leftarrow tanh \\\\\n",
    "\\hat{y_t} = g_2(W_{ya}a_t + b_y) \\leftarrow bin/softmax $$\n",
    "\n",
    "#### 反向传播BPTT\n",
    "\n",
    "RNN的反向传播使用的很经典的BPTT方法(Back Propagation Through Time).\n",
    "\n",
    "首先, 下图列出RNN结构的正向传播的数据流动方向, 反向传播时, 就是沿着正向的方向, 使用链式求导法则反向计算.\n",
    "\n",
    "<img src=\"src/pictures/c5_w1_2.png\" width=50%>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
